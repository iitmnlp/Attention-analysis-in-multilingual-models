{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FineTuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU5hqsQe2AMT"
      },
      "source": [
        "#This cell checks out the latest revision of the XGLUE code.\n",
        "#The data for the tasks in XGLUE can be obtained from https://microsoft.github.io/XGLUE/\n",
        "\n",
        "!git clone https://github.com/microsoft/Unicoder\n",
        "%cd Unicoder\n",
        "!git reset --hard 149d8a4\n",
        "%cd understanding\n",
        "!pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsJuMXCmHmk2",
        "outputId": "a2afdb5f-f53d-4e6d-a7b5-1517acb387f3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuyCvs6eorW0"
      },
      "source": [
        "**NC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4RaXABVHBoV"
      },
      "source": [
        "#This cell runs the news classification task using the XGLUE code.\n",
        "#data_dir: path containing the train,dev and test files for this task.\n",
        "#otuput_dir: path where the fine tuned model has to be persisted.\n",
        "\n",
        "!python examples/run_xglue.py --model_type bert \\\n",
        "--model_name_or_path 'bert-base-multilingual-cased' \\\n",
        "--language de,en,es,fr,ru \\\n",
        "--train_language en \\\n",
        "--do_train \\\n",
        "--data_dir '/content/drive/My Drive/XGLUE/NC' \\\n",
        "--per_gpu_train_batch_size 32 \\\n",
        "--learning_rate 5e-6 \\\n",
        "--num_train_epochs 10 \\\n",
        "--max_seq_length 256 \\\n",
        "--output_dir '/content/drive/My Drive/XGLUE/Test' \\\n",
        "--task_name news \\\n",
        "--save_steps -1 \\\n",
        "--overwrite_output_dir \\\n",
        "--evaluate_during_training \\\n",
        "--logging_steps -1 \\\n",
        "--logging_steps_in_sample -1 \\\n",
        "--logging_each_epoch \\\n",
        "--gpu_id 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg9Xjtn1ouSG"
      },
      "source": [
        "**XNLI**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coonVIilhaja"
      },
      "source": [
        "#This cell runs the XNLI task using the XGLUE code. To fine tune on different languages, just change the train_language.\n",
        "#data_dir: path containing the train,dev and test files for this task.\n",
        "#otuput_dir: path where the fine tuned model has to be persisted.\n",
        "\n",
        "!python examples/run_xglue.py --model_type bert \\\n",
        "--model_name_or_path 'bert-base-multilingual-cased' \\\n",
        "--language ar,bg,de,el,en,es,fr,hi,ru,sw,th,tr,ur,vi,zh \\\n",
        "--train_language en \\\n",
        "--do_train \\\n",
        "--data_dir '/content/drive/My Drive/XGLUE/XNLI' \\\n",
        "--per_gpu_train_batch_size 32 \\\n",
        "--learning_rate 5e-6 \\\n",
        "--num_train_epochs 10 \\\n",
        "--max_seq_length 256 \\\n",
        "--output_dir '/content/drive/My Drive/XGLUE/Test' \\\n",
        "--task_name xnli \\\n",
        "--save_steps -1 \\\n",
        "--overwrite_output_dir \\\n",
        "--evaluate_during_training \\\n",
        "--logging_steps -1 \\\n",
        "--logging_steps_in_sample -1 \\\n",
        "--logging_each_epoch \\\n",
        "--gpu_id 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zNua3v2owXr"
      },
      "source": [
        "**PAWSX**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbNb2kXwoo48"
      },
      "source": [
        "#This cell runs the PAWSX task using the XGLUE code.\n",
        "#data_dir: path containing the train,dev and test files for this task.\n",
        "#otuput_dir: path where the fine tuned model has to be persisted.\n",
        "\n",
        "!python examples/run_xglue.py --model_type bert \\\n",
        "--model_name_or_path 'bert-base-multilingual-cased' \\\n",
        "--language de,en,es,fr \\\n",
        "--train_language en \\\n",
        "--do_train \\\n",
        "--data_dir '/content/drive/My Drive/XGLUE/PAWSX' \\\n",
        "--per_gpu_train_batch_size 32 \\\n",
        "--learning_rate 5e-6 \\\n",
        "--num_train_epochs 10 \\\n",
        "--max_seq_length 256 \\\n",
        "--output_dir '/content/drive/My Drive/XGLUE/Test' \\\n",
        "--task_name pawsx \\\n",
        "--save_steps -1 \\\n",
        "--overwrite_output_dir \\\n",
        "--evaluate_during_training \\\n",
        "--logging_steps -1 \\\n",
        "--logging_steps_in_sample -1 \\\n",
        "--logging_each_epoch \\\n",
        "--gpu_id 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZljguh0QfqP"
      },
      "source": [
        "**QADSM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQB9jHfIQeZe"
      },
      "source": [
        "#This cell runs the QADSM task using the XGLUE code.\n",
        "#data_dir: path containing the train,dev and test files for this task.\n",
        "#otuput_dir: path where the fine tuned model has to be persisted.\n",
        "\n",
        "!python examples/run_xglue.py --model_type bert \\\n",
        "--model_name_or_path 'bert-base-multilingual-cased' \\\n",
        "--language de,en,fr \\\n",
        "--train_language en \\\n",
        "--do_train \\\n",
        "--data_dir '/content/drive/My Drive/XGLUE/QADSM' \\\n",
        "--per_gpu_train_batch_size 32 \\\n",
        "--learning_rate 5e-6 \\\n",
        "--num_train_epochs 10 \\\n",
        "--max_seq_length 256 \\\n",
        "--output_dir '/content/drive/My Drive/XGLUE/Test' \\\n",
        "--task_name ads \\\n",
        "--save_steps -1 \\\n",
        "--overwrite_output_dir \\\n",
        "--evaluate_during_training \\\n",
        "--logging_steps -1 \\\n",
        "--logging_steps_in_sample -1 \\\n",
        "--logging_each_epoch \\\n",
        "--gpu_id 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxbvFWL_iWiK"
      },
      "source": [
        "**QAM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbFlMedSiYk1"
      },
      "source": [
        "#This cell runs the QAM task using the XGLUE code.\n",
        "#data_dir: path containing the train,dev and test files for this task.\n",
        "#otuput_dir: path where the fine tuned model has to be persisted.\n",
        "\n",
        "!python examples/run_xglue.py --model_type bert \\\n",
        "--model_name_or_path 'bert-base-multilingual-cased' \\\n",
        "--language de,en,fr \\\n",
        "--train_language en \\\n",
        "--do_train \\\n",
        "--data_dir '/content/drive/My Drive/XGLUE/QAM' \\\n",
        "--per_gpu_train_batch_size 32 \\\n",
        "--learning_rate 5e-6 \\\n",
        "--num_train_epochs 10 \\\n",
        "--max_seq_length 256 \\\n",
        "--output_dir '/content/drive/My Drive/XGLUE/Test' \\\n",
        "--task_name qam \\\n",
        "--save_steps -1 \\\n",
        "--overwrite_output_dir \\\n",
        "--evaluate_during_training \\\n",
        "--logging_steps -1 \\\n",
        "--logging_steps_in_sample -1 \\\n",
        "--logging_each_epoch \\\n",
        "--gpu_id 0"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}